{"cells":[{"cell_type":"markdown","metadata":{"id":"83eE0RnNYnkJ"},"source":["# SNA - Project in Google Colab\n","\n","## Colab Preparation\n","\n","**Keep Alive**\n","\n","When training google colab tends to kick you out, This might help: https://medium.com/@shivamrawat_756/how-to-prevent-google-colab-from-disconnecting-717b88a128c0\n","\n","**Get Started**\n","\n","Run the following script to mount google drive and install needed python packages. Pytorch comes pre-installed."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rwJkMc3zYm0V","outputId":"15081ac4-79d3-4a3d-b3e6-81a7e346e746","executionInfo":{"status":"ok","timestamp":1736948807738,"user_tz":-60,"elapsed":42644,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zGuRDrs7aNWR","outputId":"1a987da5-0660-4617-90ee-a2b9ddbc7d62","executionInfo":{"status":"ok","timestamp":1736948807738,"user_tz":-60,"elapsed":9,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/sna\n"]}],"source":["%cd /content/drive/MyDrive/sna/"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPPVwuc3bBS6","outputId":"f1cfacaf-209b-431c-a992-47c6c2821aef","executionInfo":{"status":"ok","timestamp":1736948807739,"user_tz":-60,"elapsed":8,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["archive\t\t     graph.pkl\t\t\t\t     GraphSage-LinkPrediction.ipynb\n","data\t\t     GraphSage_LinkPrediction21.ipynb\t     node2vec_colab.ipynb\n","exploratory\t     GraphSage_LinkPrediction22-Copy1.ipynb  node2vec.ipynb\n","graph_directed2.pkl  GraphSage_LinkPrediction22.ipynb\t     README.md\n","graph_directed.pkl   GraphSage-LinkPrediction2.ipynb\t     similarity_based.ipynb\n"]}],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"Hl69JAe4zuq_"},"source":["#### Install libraries"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gu5HiXJ1ZLRY","outputId":"32ecdde9-04a1-4599-b379-16f9df84d785","executionInfo":{"status":"ok","timestamp":1736948957758,"user_tz":-60,"elapsed":150023,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.dgl.ai/wheels/torch-2.3/repo.html\n","Collecting dgl\n","  Downloading https://data.dgl.ai/wheels/torch-2.3/dgl-2.4.0-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.4.2)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dgl) (24.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgl) (2.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.10.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from dgl) (6.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.13.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.67.1)\n","Collecting torch<=2.4.0 (from dgl)\n","  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (2.27.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.12.14)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.16.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<=2.4.0->dgl)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<=2.4.0->dgl)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<=2.4.0->dgl)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<=2.4.0->dgl)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<=2.4.0->dgl)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<=2.4.0->dgl)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch<=2.4.0->dgl)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<=2.4.0->dgl)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<=2.4.0->dgl)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch<=2.4.0->dgl)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch<=2.4.0->dgl)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==3.0.0 (from torch<=2.4.0->dgl)\n","  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0->dgl) (12.6.85)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<=2.4.0->dgl) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n","Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, dgl\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n","    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu121\n","    Uninstalling torch-2.5.1+cu121:\n","      Successfully uninstalled torch-2.5.1+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.4.0 which is incompatible.\n","torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed dgl-2.4.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0 triton-3.0.0\n"]}],"source":["!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/repo.html"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"n6LXIVp_hWik","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736948961198,"user_tz":-60,"elapsed":3444,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}},"outputId":"624e9ca9-ff4a-450c-c378-95337782d1f4"},"outputs":[{"output_type":"stream","name":"stderr","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n"]},{"output_type":"stream","name":"stdout","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]}],"source":["import dgl\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import itertools\n","import numpy as np\n","import scipy.sparse as sp\n","import pickle"]},{"cell_type":"markdown","metadata":{"id":"u4Z1jslRhWil"},"source":["### 1. Link prediction with GNN\n","Assume we are given a graph g with incomplete data, for example, only 50% of the edges are present.\n","\n","The goal is to predict **whether there is an edge** between any 2 nodes in g."]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GmHAILS9fLW7","outputId":"a08a5810-5531-4bb0-a6d2-1bae319265c1","executionInfo":{"status":"ok","timestamp":1736949293921,"user_tz":-60,"elapsed":7293,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of nodes: 10964\n","Number of edges: 1058868\n","Edge data keys: dict_keys(['count'])\n"]}],"source":["import pickle\n","\n","# Load the graph\n","with open('graph_directed.pkl', 'rb') as f:\n","    g = pickle.load(f)\n","\n","# # Convert to DGL graph if necessary\n","# if not isinstance(g, dgl.DGLGraph):\n","#     g = dgl.from_networkx(g)\n","g = dgl.from_networkx(g, edge_attrs=['count'])\n","\n","# Verify the loaded graph\n","print(f\"Number of nodes: {g.number_of_nodes()}\")\n","print(f\"Number of edges: {g.number_of_edges()}\")\n","print(\"Edge data keys:\", g.edata.keys())\n"]},{"cell_type":"markdown","metadata":{"id":"0PKfuYKRRDpg"},"source":["Transforming Edge features into Node Features"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JnR1IFEDSrK9","outputId":"e7c7b809-20f5-4adf-e84a-a512bf246fa1","executionInfo":{"status":"ok","timestamp":1736949328863,"user_tz":-60,"elapsed":34946,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Node features (aggregated edge counts):\n"," tensor([[ 6.],\n","        [36.],\n","        [26.],\n","        ...,\n","        [ 2.],\n","        [ 4.],\n","        [16.]])\n"]}],"source":["import torch\n","\n","# Initialize node features as zeros\n","num_nodes = g.num_nodes()\n","node_features = torch.zeros((num_nodes, 1))  # One-dimensional node features\n","\n","# Aggregate edge counts into node features\n","for src, dst, edge_data in zip(*g.edges(), g.edata['count']):\n","    node_features[src] += edge_data\n","    node_features[dst] += edge_data  # Assuming undirected graph\n","\n","# Assign aggregated features to nodes\n","g.ndata['feat'] = node_features\n","print(\"Node features (aggregated edge counts):\\n\", g.ndata['feat'])"]},{"cell_type":"markdown","metadata":{"id":"tTtTBAtrT6Ij"},"source":["Train/test split and obtaining positive edges"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"R8MWzP1DT-VA","executionInfo":{"status":"ok","timestamp":1736949328863,"user_tz":-60,"elapsed":5,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[],"source":["np.random.seed(42)  # For reproducibility\n","edge_ids = np.arange(g.num_edges())\n","edge_ids = np.random.permutation(edge_ids)\n","\n","train_size = int(0.8 * len(edge_ids))\n","train_mask = edge_ids[:train_size]\n","test_mask = edge_ids[train_size:]\n","\n","# Remove test edges to create g_main\n","g_main = dgl.remove_edges(g, test_mask)\n","\n","# Extract edges\n","u, v = g.edges()\n","\n","# Positive edges for training and testing\n","train_pos_u, train_pos_v = u[train_mask], v[train_mask]\n","test_pos_u, test_pos_v = u[test_mask], v[test_mask]"]},{"cell_type":"markdown","metadata":{"id":"nt3n2ONLUFS6"},"source":["Generation of negative edges"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"FjIEDTsRUID4","executionInfo":{"status":"ok","timestamp":1736949331221,"user_tz":-60,"elapsed":2362,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[],"source":["# Create adjacency matrix\n","adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n","adj = adj.todense() + np.eye(g.num_nodes())  # Add self-loops to avoid sampling them as negatives\n","\n","# Get non-edges\n","u_neg, v_neg = np.where(adj == 0)\n","\n","# Sample negative edges\n","neg_ids = np.random.choice(len(u_neg), len(u))\n","train_neg_u, train_neg_v = u_neg[neg_ids[:train_size]], v_neg[neg_ids[:train_size]]\n","test_neg_u, test_neg_v = u_neg[neg_ids[train_size:]], v_neg[neg_ids[train_size:]]"]},{"cell_type":"markdown","metadata":{"id":"iPHOKoYdUKws"},"source":["Train/test graph creation"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"si1qJrHuUNXa","executionInfo":{"status":"ok","timestamp":1736949331221,"user_tz":-60,"elapsed":10,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[],"source":["# # Training graphs\n","# g_train_pos = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.num_nodes())\n","# g_train_neg = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.num_nodes())\n","\n","# # Testing graphs\n","# g_test_pos = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.num_nodes())\n","# g_test_neg = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.num_nodes())\n","\n","# Training graphs\n","g_train_pos = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.num_nodes())\n","g_train_pos.edata['count'] = g.edata['count'][train_mask]  # Copy 'count' attribute\n","\n","g_train_neg = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.num_nodes())\n","g_train_neg.edata['count'] = torch.zeros(train_neg_u.shape[0])  # No count for negative edges\n","\n","# Testing graphs\n","g_test_pos = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.num_nodes())\n","g_test_pos.edata['count'] = g.edata['count'][test_mask]  # Copy 'count' attribute\n","\n","g_test_neg = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.num_nodes())\n","g_test_neg.edata['count'] = torch.zeros(test_neg_u.shape[0])  # No count for negative edges\n"]},{"cell_type":"markdown","metadata":{"id":"0h6GJgw8hWit"},"source":["### 2. GNN with SageConv\n","dgl.nn.SAGEConv(in_dim, out_dim) updates in the following way\n","\n","\\begin{align*}\n","h_i^{(l+1)}&= W.\\text{concat}(h_i^{(l)},h_{N(i)}^{(l+1)})+b \\ \\text{with} \\\\ h_{N(i)}^{(l+1)}&=\\text{Mean}\\{h_j^{(l)}, j\\in N(i)\\}\n","\\end{align*}\n","\n","Here is our **model structure**\n","<center>\n","input -> SAGEConv1 -> relu -> SAGEConv2 -> predictor\n","<end><center>\n"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"sswZC_Saanus","executionInfo":{"status":"ok","timestamp":1736953536115,"user_tz":-60,"elapsed":354,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[],"source":["# slightly changed architecture\n","import dgl.function as fn\n","from dgl.nn import SAGEConv\n","\n","from sklearn.metrics import roc_auc_score # for computing auc metric\n","\n","class GraphSage(nn.Module):\n","    def __init__(self, in_dim, hidden_dim):\n","        super().__init__()\n","        self.conv1 = SAGEConv(in_dim, hidden_dim, aggregator_type=\"mean\")\n","        self.conv2 = SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\")\n","\n","    def forward(self, g, features):\n","        h = self.conv1(g, features)\n","        h = F.relu(h)\n","        h = self.conv2(g, h)\n","        return h\n","\n","    def predict(self, g, h):\n","        with g.local_scope():\n","            g.ndata['h'] = h\n","            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))  # Compute edge scores\n","            return g.edata['score'].squeeze()  # Ensure the result is 1D\n","\n","\n","    def loss(self, pos_scores, neg_scores):\n","        # Combine positive and negative scores\n","        scores = torch.cat([pos_scores, neg_scores])\n","        # Create labels: 1 for positive edges, 0 for negative edges\n","        labels = torch.cat([torch.ones(pos_scores.shape[0]), torch.zeros(neg_scores.shape[0])])\n","        # Compute binary cross-entropy loss\n","        return F.binary_cross_entropy_with_logits(scores, labels)\n","\n","    def auc_score(self, pos_scores, neg_scores):\n","        scores = torch.cat([pos_scores, neg_scores]).detach().numpy()\n","        labels = torch.cat([torch.ones(pos_scores.shape[0]), torch.zeros(neg_scores.shape[0])]).detach().numpy()\n","        return roc_auc_score(labels, scores)"]},{"cell_type":"markdown","metadata":{"id":"bE9SkNM3hWiu"},"source":["### 3. Train and Test"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"gVGRqSPKaw-C","executionInfo":{"status":"ok","timestamp":1736953647000,"user_tz":-60,"elapsed":329,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","def train(model, g_main, g_train_pos, g_train_neg, optimizer):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    # Forward pass\n","    h = model(g_main, g_main.ndata['feat'])\n","\n","    # Predict scores for positive and negative training edges\n","    pos_scores = model.predict(g_train_pos, h)\n","    neg_scores = model.predict(g_train_neg, h)\n","\n","    # Calculate loss\n","    loss = model.loss(pos_scores, neg_scores)\n","\n","    # Backward pass and optimization\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Combine scores and labels for AUC and accuracy\n","    scores = torch.cat([pos_scores, neg_scores]).detach().numpy()\n","    labels = torch.cat([torch.ones(pos_scores.shape[0]), torch.zeros(neg_scores.shape[0])]).detach().numpy()\n","\n","    # Compute ROC AUC\n","    auc = roc_auc_score(labels, scores)\n","\n","    # Compute Accuracy (using threshold = 0.5)\n","    predicted_labels = (scores >= 0.5).astype(int)\n","    accuracy = accuracy_score(labels, predicted_labels)\n","\n","    return loss.item(), auc, accuracy\n"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","@torch.no_grad()\n","def evaluate(model, g_main, g_test_pos, g_test_neg):\n","    model.eval()\n","    h = model(g_main, g_main.ndata['feat'])\n","\n","    # Predict scores for positive and negative test edges\n","    pos_scores = model.predict(g_test_pos, h)\n","    neg_scores = model.predict(g_test_neg, h)\n","\n","    # Calculate loss\n","    loss = model.loss(pos_scores, neg_scores)\n","\n","    # Combine scores and labels for AUC and accuracy\n","    scores = torch.cat([pos_scores, neg_scores]).detach().numpy()\n","    labels = torch.cat([torch.ones(pos_scores.shape[0]), torch.zeros(neg_scores.shape[0])]).detach().numpy()\n","\n","    # Compute ROC AUC\n","    auc = roc_auc_score(labels, scores)\n","\n","    # Compute Accuracy (using threshold = 0.5)\n","    predicted_labels = (scores >= 0.5).astype(int)\n","    accuracy = accuracy_score(labels, predicted_labels)\n","\n","    return loss.item(), auc, accuracy"],"metadata":{"id":"e-MH8uH2ftLK","executionInfo":{"status":"ok","timestamp":1736953661388,"user_tz":-60,"elapsed":222,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","execution_count":51,"metadata":{"id":"VJd75lndbEMW","executionInfo":{"status":"ok","timestamp":1736953662363,"user_tz":-60,"elapsed":4,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[],"source":["# new hyperparams and initialization of the model\n","from torch.optim import Adam\n","\n","# initialize model and optimizer\n","in_dim = g_main.ndata['feat'].shape[1]\n","hidden_dim = 16\n","model = GraphSage(in_dim, hidden_dim)\n","optimizer = Adam(model.parameters(), lr=0.01)"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r1gFCrKfd-Pq","outputId":"0298562e-7f02-4e0e-97f6-3a83c7c09b5f","executionInfo":{"status":"ok","timestamp":1736953665133,"user_tz":-60,"elapsed":215,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Edge data in g_main: dict_keys(['count'])\n","Edge data in g_train_pos: dict_keys(['count'])\n","Edge data in g_train_neg: dict_keys(['count'])\n"]}],"source":["print(\"Edge data in g_main:\", g_main.edata.keys())\n","print(\"Edge data in g_train_pos:\", g_train_pos.edata.keys())\n","print(\"Edge data in g_train_neg:\", g_train_neg.edata.keys())\n"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHrmRg5ZboXA","outputId":"0f560995-a0e3-4de7-b2a0-153a8e8e21d5","executionInfo":{"status":"ok","timestamp":1736953691502,"user_tz":-60,"elapsed":24238,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Loss: 3974002.7500, AUC: 0.6718, Accuracy: 0.5006\n","Epoch 2/50, Loss: 3190918.7500, AUC: 0.6815, Accuracy: 0.5013\n","Epoch 3/50, Loss: 2540643.5000, AUC: 0.6943, Accuracy: 0.5033\n","Epoch 4/50, Loss: 2007348.5000, AUC: 0.7097, Accuracy: 0.5068\n","Epoch 5/50, Loss: 1574263.1250, AUC: 0.7261, Accuracy: 0.5087\n","Epoch 6/50, Loss: 1226983.1250, AUC: 0.7413, Accuracy: 0.5094\n","Epoch 7/50, Loss: 951711.5625, AUC: 0.7541, Accuracy: 0.5097\n","Epoch 8/50, Loss: 734233.4375, AUC: 0.7643, Accuracy: 0.5099\n","Epoch 9/50, Loss: 563588.8750, AUC: 0.7730, Accuracy: 0.5101\n","Epoch 10/50, Loss: 430882.0938, AUC: 0.7807, Accuracy: 0.5096\n","Epoch 11/50, Loss: 328680.3438, AUC: 0.7867, Accuracy: 0.5091\n","Epoch 12/50, Loss: 251015.7188, AUC: 0.7907, Accuracy: 0.5092\n","Epoch 13/50, Loss: 193044.0781, AUC: 0.7926, Accuracy: 0.5114\n","Epoch 14/50, Loss: 150632.8438, AUC: 0.7927, Accuracy: 0.5168\n","Epoch 15/50, Loss: 120352.7266, AUC: 0.7914, Accuracy: 0.5259\n","Epoch 16/50, Loss: 99347.0469, AUC: 0.7893, Accuracy: 0.5379\n","Epoch 17/50, Loss: 85250.2656, AUC: 0.7870, Accuracy: 0.5521\n","Epoch 18/50, Loss: 76134.4141, AUC: 0.7853, Accuracy: 0.5669\n","Epoch 19/50, Loss: 70540.7578, AUC: 0.7846, Accuracy: 0.5806\n","Epoch 20/50, Loss: 67378.2578, AUC: 0.7849, Accuracy: 0.5904\n","Epoch 21/50, Loss: 65780.5078, AUC: 0.7851, Accuracy: 0.5962\n","Epoch 22/50, Loss: 65116.7031, AUC: 0.7851, Accuracy: 0.5987\n","Epoch 23/50, Loss: 64950.9336, AUC: 0.7849, Accuracy: 0.5991\n","Epoch 24/50, Loss: 64993.3320, AUC: 0.7847, Accuracy: 0.5982\n","Epoch 25/50, Loss: 65049.5195, AUC: 0.7845, Accuracy: 0.5967\n","Epoch 26/50, Loss: 64993.7617, AUC: 0.7845, Accuracy: 0.5948\n","Epoch 27/50, Loss: 64753.1094, AUC: 0.7844, Accuracy: 0.5927\n","Epoch 28/50, Loss: 64292.8320, AUC: 0.7845, Accuracy: 0.5907\n","Epoch 29/50, Loss: 63605.5508, AUC: 0.7845, Accuracy: 0.5887\n","Epoch 30/50, Loss: 62699.6250, AUC: 0.7846, Accuracy: 0.5867\n","Epoch 31/50, Loss: 61595.1680, AUC: 0.7846, Accuracy: 0.5849\n","Epoch 32/50, Loss: 60320.9648, AUC: 0.7846, Accuracy: 0.5831\n","Epoch 33/50, Loss: 58911.0938, AUC: 0.7845, Accuracy: 0.5816\n","Epoch 34/50, Loss: 57402.5312, AUC: 0.7844, Accuracy: 0.5802\n","Epoch 35/50, Loss: 55829.8320, AUC: 0.7843, Accuracy: 0.5792\n","Epoch 36/50, Loss: 54226.7852, AUC: 0.7842, Accuracy: 0.5785\n","Epoch 37/50, Loss: 52623.4414, AUC: 0.7841, Accuracy: 0.5780\n","Epoch 38/50, Loss: 51043.1250, AUC: 0.7840, Accuracy: 0.5777\n","Epoch 39/50, Loss: 49502.0703, AUC: 0.7839, Accuracy: 0.5777\n","Epoch 40/50, Loss: 48011.9766, AUC: 0.7839, Accuracy: 0.5780\n","Epoch 41/50, Loss: 46576.7031, AUC: 0.7840, Accuracy: 0.5785\n","Epoch 42/50, Loss: 45195.5234, AUC: 0.7844, Accuracy: 0.5793\n","Epoch 43/50, Loss: 43864.3281, AUC: 0.7850, Accuracy: 0.5804\n","Epoch 44/50, Loss: 42577.4375, AUC: 0.7858, Accuracy: 0.5820\n","Epoch 45/50, Loss: 41330.7695, AUC: 0.7869, Accuracy: 0.5841\n","Epoch 46/50, Loss: 40120.9102, AUC: 0.7882, Accuracy: 0.5863\n","Epoch 47/50, Loss: 38945.2422, AUC: 0.7897, Accuracy: 0.5891\n","Epoch 48/50, Loss: 37804.6328, AUC: 0.7914, Accuracy: 0.5922\n","Epoch 49/50, Loss: 36701.5430, AUC: 0.7931, Accuracy: 0.5956\n","Epoch 50/50, Loss: 35639.6719, AUC: 0.7950, Accuracy: 0.5994\n"]}],"source":["# new training loop\n","num_epochs = 50\n","for epoch in range(num_epochs):\n","    train_loss, train_auc, train_accuracy = train(model, g_main, g_train_pos, g_train_neg, optimizer)\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, AUC: {train_auc:.4f}, Accuracy: {train_accuracy:.4f}\")"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50d24M7shWiw","outputId":"6c2c7db0-01a4-47a1-d4ad-98ba5e01c5f0","executionInfo":{"status":"ok","timestamp":1736953693183,"user_tz":-60,"elapsed":420,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 34780.7109 | Test AUC: 0.7969 | Test Accuracy: 0.6038\n"]}],"source":["# Evaluate on the test graph\n","with torch.no_grad():\n","    test_loss, test_auc, test_accuracy = evaluate(model, g_main, g_test_pos, g_test_neg)\n","    print(f\"Test Loss: {test_loss:.4f} | Test AUC: {test_auc:.4f} | Test Accuracy: {test_accuracy:.4f}\")"]},{"cell_type":"markdown","source":["#### Save the model"],"metadata":{"id":"b7lFQzQ_gpaP"}},{"cell_type":"code","source":["# Save the model state\n","torch.save(model.state_dict(), 'graphsage_model.pth')\n","print(\"Model saved as 'graphsage_model.pth'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kDDrymSDguke","executionInfo":{"status":"ok","timestamp":1736953762622,"user_tz":-60,"elapsed":228,"user":{"displayName":"Anastasia Cissa","userId":"13518821841121509014"}},"outputId":"3e523e55-92eb-4ae2-e258-5394d4a3c887"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved as 'graphsage_model.pth'\n"]}]},{"cell_type":"markdown","metadata":{"id":"_thHpZyUhWiw"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":0}